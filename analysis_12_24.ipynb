{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import MeCab\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EOS\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = MeCab.Tagger(\"-Ochasen -d /usr/local/lib/mecab/dic/mecab-ipadic-neologd -u /Users/yuki/foo/bar/user_dic2.dic\")\n",
    "tagger.parse(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\"♦\",\"▪\",\"⚪\",\"・\",\"◾\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_ja(text):\n",
    "    node = tagger.parseToNode(str(text)) #分かち書きしたのが入っている。イテレータ\n",
    "    while node:\n",
    "        surface = node.surface.lower() #surfaceは単語の見た目　例：トろ\n",
    "        feature = node.feature.split(\",\")\n",
    "        hinshi = feature[0]\n",
    "        genkei = feature[6]\n",
    "        if surface not in stop_words and surface != \"\" and hinshi in [\"形容詞\", \"動詞\", \"副詞\", \"助動詞\", \"接続詞\", \"連体詞\", \"感動詞\", \"接頭詞\"]:\n",
    "            yield genkei\n",
    "        elif surface not in stop_words and surface != \"\" and hinshi == \"名詞\":\n",
    "            yield surface\n",
    "        node = node.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_ja_2(text):\n",
    "    node = tagger.parseToNode(str(text)) #分かち書きしたのが入っている。イテレータ\n",
    "    while node:\n",
    "        surface = node.surface.lower() #surfaceは単語の見た目　例：トろ\n",
    "        feature = node.feature.split(\",\")\n",
    "        hinshi = feature[0]\n",
    "        genkei = feature[6]\n",
    "        if surface not in stop_words and surface != \"\" and hinshi in [\"形容詞\", \"動詞\", \"副詞\", \"助動詞\", \"接続詞\", \"連体詞\", \"感動詞\", \"接頭詞\"]:\n",
    "            yield (genkei, hinshi)\n",
    "        elif surface not in stop_words and surface != \"\" and hinshi == \"名詞\":\n",
    "            yield (surface, hinshi)\n",
    "        node = node.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(content):\n",
    "    return [token for token in tokenize_ja(content)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_2(content):\n",
    "    return [token for token in tokenize_ja_2(content)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_df(file, jiku_list, n, t, s):\n",
    "    store_name = file.replace(\"../pretest_\", \"\").replace(\".csv\", \"\")\n",
    "    df = pd.read_csv(file)\n",
    "    num_word = 0 #全単語数を保存\n",
    "    word_dict = defaultdict(int) #登場単語とその回数を保存\n",
    "    if \"dinner\" in file:\n",
    "        all_words = all_review_word_dinner_2 #他の店の登場単語とその回数の辞書\n",
    "        all_num_words = num_word_dinner_2\n",
    "        review_list = df[\"dinner_review\"]\n",
    "        for review in review_list:\n",
    "            li = tokenize(review)\n",
    "            for i in li:\n",
    "                word_dict[i] += 1\n",
    "                num_word += 1\n",
    "    elif \"lunch\" in file:\n",
    "        all_words = all_review_word_lunch_2 #他の店の登場単語とその回数の辞書\n",
    "        all_num_words = num_word_lunch_2\n",
    "        review_list = df[\"lunch_review\"]\n",
    "        for review in review_list:\n",
    "            li = tokenize(review)\n",
    "            for i in li:\n",
    "                word_dict[i] += 1\n",
    "                num_word += 1\n",
    "    word_info = [] #軸に関する単語の出力情報を渡す のちにDataFrame化する\n",
    "    for jiku_word_list in jiku_list:\n",
    "        for ii in range(1, len(jiku_word_list)):\n",
    "            w = jiku_word_list[ii]\n",
    "            if word_dict[w]/num_word > (all_words[w]/all_num_words) * t:\n",
    "                #他の店よりwという単語がt倍登場している時\n",
    "                kyouki_pare = n_gram_result(w, n, review_list) #n_gramを使って出した共起度\n",
    "                pare_word_list = [i[0][1] for i in kyouki_pare]\n",
    "                pare_word_list.extend([\"*\" for i in range(s)])\n",
    "                pare_word_time_list = [i[1] for i in kyouki_pare]\n",
    "                pare_word_time_list.extend([\"*\" for i in range(s)])\n",
    "                l = [jiku_word_list[0],\n",
    "                     w,\n",
    "                     word_dict[w], \n",
    "                    int(10000*word_dict[w]/num_word)/100,\n",
    "                    int(100*word_dict[w]/len(review_list))/100,\n",
    "                    int(10000*all_words[w]/all_num_words)/100,\n",
    "                     ]\n",
    "                l.extend([pare_word_list[i] +\"　\" +str(pare_word_time_list[i]) for i in range(s)])\n",
    "                word_info.append(l)\n",
    "    columns = [\"軸\",\"単語\",\"登場数\",\"登場率%/\"+str(num_word),\"レビューあたり/\"+str(len(review_list)),\"他のレビューでの登場率%\"]\n",
    "    columns.extend([i+1 for i in range(s)])\n",
    "    df = pd.DataFrame(word_info, columns=columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_csv(file, n, t, s):\n",
    "    store_name=file.replace(\"../pretest_\", \"\").replace(\".csv\", \"\")\n",
    "    df = output_df(file,jiku_list,n, t, s)\n",
    "    df.to_csv(store_name+str(t)+\"times\"+str(n)+\"_gram.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_sentence_csv(file, t, s):\n",
    "    store_name=file.replace(\"../pretest_\", \"\").replace(\".csv\", \"\")\n",
    "    df = output_df(file,jiku_list,50, t, s)\n",
    "    df.to_csv(store_name+str(t)+\"times_sentence.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in store_file:\n",
    "    output_csv(file,5,2.5,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in store_file:\n",
    "    output_sentence_csv(file,1,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in store_file:\n",
    "    output_sentence_csv(file,1.5,20)\n",
    "    output_sentence_csv(file,2,20)\n",
    "    output_sentence_csv(file,2.5,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_gram(n, text):\n",
    "    all_result = []\n",
    "    texts = text.split(\"。\")\n",
    "    for text in texts:\n",
    "        \n",
    "        a = [(\"*\", \"*\") for i in range(n)]\n",
    "        a.extend(tokenize_2(text))\n",
    "        a.extend([(\"*\", \"*\") for i in range(n)])\n",
    "        result = []\n",
    "        for i in range(n,len(a) - n + 1):\n",
    "            result.append(a[i-n:i+n+1])\n",
    "        all_result.extend(result)\n",
    "    return all_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_gram_result(word, n, review_list):\n",
    "    pare_time_dic = defaultdict(int)\n",
    "    if n > 0:\n",
    "        for text in review_list:\n",
    "            for gram in n_gram(n,text):\n",
    "                if word == gram[n][0]:\n",
    "                    for g in gram:\n",
    "                        if word != g[0] and g[0] != \"*\" and (g[1] == \"形容詞\" or g[1] == \"名詞\" or g[1] == \"動詞\"):\n",
    "                            pare_time_dic[(word, g[0])] += 1\n",
    "                        #if g[0] != word and g[0] != \"*\" :\n",
    "                            #pare_time_dic[(word, g[0])] += 1\n",
    "    counter = Counter(pare_time_dic)\n",
    "    common = counter.most_common()\n",
    "    return common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_gram_result_dinner(word, n, file, dinner):\n",
    "    pare_time_dic = defaultdict(int)\n",
    "    df = pd.read_csv(file)\n",
    "    if dinner == True:\n",
    "        for text in df[\"dinner_review\"]:\n",
    "            for gram in n_gram(n,text):\n",
    "                if word == gram[n][0]:\n",
    "                    for g in gram:\n",
    "                        #if word != g[0] and g[1] == \"形容詞\":\n",
    "                            #pare_time_dic[(word, g[0])] += 1\n",
    "                        if g[0] != word and g[0] != \"*\" :\n",
    "                            pare_time_dic[(word, g[0])] += 1\n",
    "    counter = Counter(pare_time_dic)\n",
    "    common = counter.most_common()\n",
    "    return common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "sushi = [\"鮨\",\"旨い\",\"握り\"]\n",
    "kome = [\"シャリ\",\"握り\",\"シャリ\",\"酢飯\",\"酢\",\"塩\",\n",
    "                  \"砂糖\",\"味\",\"香り\",\"硬さ\",\"炊き具合\",\n",
    "                  \"温度\",\"米\"]\n",
    "neta = [\"ネタ\",\"ネタ\",\"温度\",\"厚さ\",\"薄さ\",\"大きさ\",\"鮮度\",\"熟成\",\n",
    "                 \"くさい\",\"香り\",\"生臭い\",\"旨み\",\"甘み\",\"塩\",\n",
    "                 \"骨\",\"舌触り\",\"滑らか\",\"パサパサ\",\"漁場\",\"時期\",\n",
    "                 \"工夫\",\"締め\",\"名物\",\"魚介\",\"魚\",\"食材\",\n",
    "                 \"種類\"]\n",
    "sozai = [\"素材単体\",\"マグロ\",\"鮪\",\"大トロ\",\"ヅケマグロ\",\"コハダ\",\n",
    "                 \"イワシ\",\"カツオ\",\"アジ\",\"ウニ\",\"雲丹\",\"鯛\",\n",
    "                 \"カスゴ鯛\",\"金目鯛\",\"ヒラメ\",\"キス\",\"キンキ\",\"白魚\",\n",
    "                 \"白身魚\",\"白身\",\"鮎\",\"鰻\",\"穴子\",\"蛸\",\n",
    "                  \"真蛸\",\"イカ\",\"蛍イカ\",\"アカイカ\",\"だるまイカ\",\"車海老\",\n",
    "                  \"蟹\",\"毛蟹\",\"鮑\",\"赤貝\",\"トリ貝\",\"牡蠣\",\n",
    "                  \"カラスミ\",\"ばちこ\",\"あん肝\",\"玉締め\",\"玉子焼き\",\"玉子\",\n",
    "                  \"干瓢\",\"かんぴょう\",\"山葵\",\"つくね芋\"]\n",
    "sozai_sonota = [\"素材その他\",\"塩\",\"酢橘\",\"煮キリ\",\"赤酢\",\"煎り酒\",\n",
    "                         \"酢味噌\",\"だし\",\"鰹節\",\"ガリ\",\"魚\"]\n",
    "ryouri_sonota = [\"料理その他\",\"茶碗蒸し\"]\n",
    "dougu = [\"道具\",\"羽釜\"]\n",
    "shigoto = [\"仕事\",\"江戸前\",\"仕事\",\"技\",\"技\",\"力\",\"修行\",\"会得\", \n",
    "               \"料理\",\"供す\",\"腕\"]\n",
    "sake = [\"酒\",\"酒\",\"ワイン\",\"日本酒\",\"生ビール\"]\n",
    "tsumami = [\"つまみ\",\"酒肴\",\"つまみ\",\"刺身\",\"一品料理\"]\n",
    "teikyou = [\"提供方法\",\"握り\",\"おまかせ\",\"握る\",\"時間\",\"時\",\"同じ魚\",\n",
    "               \"品書き\",\"量\",\"好み\",\"ランチ\",\"昼\",\"夜\",\n",
    "               \"コース\",\"最初\",\"最後\"]\n",
    "hito = [\"人\",\"主\",\"店主\",\"主人\",\"大将\",\"親方\",\"女将\",\n",
    "            \"店員\",\"長男\",\"客\",\"常連\",\"一見\",\"若者\",\n",
    "            \"初代\",\"先代\",\"親方\",\"弟子\",\"二番手\",\"仲買人\",\n",
    "            \"仕入\",\"仕入先\",\"生産者\",\"業者\"]\n",
    "mise = [\"店\",\"つけ場\",\"カウンター\",\"店\",\"店舗\",\"個室\",\"店内\",\n",
    "            \"中\",\"内装\",\"外観\",\"入口\",\"広さ\",\"席数\",\n",
    "            \"寿司屋\",\"鮨店\",\"訪問\",\"季節感\"]\n",
    "koyutennmei = [\"固有店名\",\"かねさか\",\"初音鮨\"]\n",
    "gyoutai = [\"業態\",\"営業\",\"予約\"]\n",
    "kakaku = [\"価格\",\"高額\",\"控えめ\",\"明朗会計\",\"高い\",\"ランチ\",\n",
    "              \"安価\",\"cp\",\"コスパ\",\"コストパフォーマンス\",\"良心的\",\"出費\",\n",
    "              \"価格\",\"リーズナブル\",\"予算\",\"お会計\",\"金額\",\"値段\",\n",
    "              \"原価率\"]\n",
    "hunniki = [\"雰囲気\",\"寿司\",\"満足度\",\"見た目\",\"遅刻\",\"人数\",\n",
    "          \"間合い\",\"気持ち\",\"雰囲気\",\"居心地\",\"接客\",\"美味しさ\",\n",
    "          \"高級感\",\"エンターテインメント\",\"感想\",\"シーン\"]\n",
    "houmonnbi = [\"訪問日\",\"今日\",\"今年\",\"年内\",\"今回\",\"前回\",\"次回\",\n",
    "            \"再訪問\",\"再度\",\"今度\"]\n",
    "tochi = [\"土地\",\"銀座\",\"四谷\",\"横浜\",\"数寄屋橋\",\"日本橋\",\"中野坂上\",\n",
    "        \"京橋\",\"人形町\",\"山梨県\",\"金沢\",\"椎名町\",\"経堂\",\n",
    "        \"日比谷\",\"蒲田\",\"立川\",\"都内\",\"地元\",\"この地\",\n",
    "        \"産地\"]\n",
    "bunnya = [\"分野\",\"日本料理\",\"和食\",\"食べログ\",\"料理\"]\n",
    "kisetsu = [\"季節\",\"旬\",\"季節\",\"走り\",\"名残\",\"通年\",\"時期\"]\n",
    "musubi = [\"結び\",\"ごちそうさま\",\"感謝\",\"よろしくお願いいたします\",\"ご馳走様でした\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "jiku_list=[sushi,kome,neta,sozai,sozai_sonota,ryouri_sonota,dougu,shigoto,\n",
    "          sake,tsumami,teikyou,hito,mise,koyutennmei,gyoutai,kakaku,\n",
    "          hunniki,houmonnbi,tochi,bunnya,kisetsu,musubi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_file = [\"../pretest_aozora_dinner.csv\",\n",
    "             \"../pretest_mitani_lunch.csv\",\n",
    "             \"../pretest_mitani_dinner.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "lunch_file = [\"../pretest_sushitsuu_lunch.csv\",\n",
    "              \"../pretest_sushiichi_lunch.csv\",\n",
    "              \"../pretest_sawada_lunch.csv\",\n",
    "              \"../pretest_matsukan_lunch.csv\",\n",
    "              \"../pretest_kiyoda_lunch.csv\",\n",
    "              \"../pretest_imamura_lunch.csv\",\n",
    "              \"../pretest_hatsune_lunch.csv\"\n",
    "              ]\n",
    "dinner_file = [\"../pretest_sushitsuu_dinner.csv\",\n",
    "              \"../pretest_sushiichi_dinner.csv\",\n",
    "              \"../pretest_sawada_dinner.csv\",\n",
    "              \"../pretest_matsukan_dinner.csv\",\n",
    "              \"../pretest_kiyoda_dinner.csv\",\n",
    "              \"../pretest_imamura_dinner.csv\",\n",
    "              \"../pretest_hatsune_dinner.csv\",\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_review_word_lunch_2 = defaultdict(int)\n",
    "all_review_word_dinner_2  =defaultdict(int)\n",
    "num_word_lunch_2 = 0\n",
    "num_word_dinner_2 = 0\n",
    "for file in lunch_file:\n",
    "    df=pd.read_csv(file)\n",
    "    for review in df[\"lunch_review\"]:\n",
    "        list=tokenize(review)\n",
    "        for l in list:\n",
    "            all_review_word_lunch_2[l] += 1 #その単語の登場回数を1加える\n",
    "            num_word_lunch_2 += 1\n",
    "for file in dinner_file:\n",
    "    df=pd.read_csv(file)\n",
    "    for review in df[\"dinner_review\"]:\n",
    "        list=tokenize(review)\n",
    "        for l in list:\n",
    "            all_review_word_dinner_2[l] += 1 #その単語の登場回数を1加える\n",
    "            num_word_dinner_2 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103058"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_word_lunch_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1088"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_review_word_lunch_2[\"シャリ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_review_df = pd.read_csv(\"../processed_all_results.csv\")\n",
    "all_review_word_lunch = defaultdict(int) #全てのレビューの登場単語をkey,その登場回数をvalue\n",
    "                                   #にした辞書\n",
    "all_review_word_dinner = defaultdict(int)\n",
    "#all_review_wordを作成していく\n",
    "#総単語数をnum_wordとする\n",
    "num_word_lunch = 0\n",
    "num_word_dinner = 0\n",
    "for i in range(len(all_review_df)):\n",
    "    l_review = all_review_df.iloc[i][\"lunch_review\"] #i番目のlunch_review\n",
    "    d_review = all_review_df.iloc[i][\"dinner_review\"] #i番目のdinner_review\n",
    "    if type(l_review) != float: #nanのときは型がfloatになる\n",
    "        list = tokenize(l_review) #形態素解析\n",
    "        for l in list:\n",
    "            all_review_word_lunch[l] += 1 #その単語の登場回数を1加える\n",
    "            num_word_lunch += 1\n",
    "    if type(d_review) != float: #nanのときは型がfloatになる\n",
    "        list = tokenize(d_review) #形態素解析\n",
    "        for l in list:\n",
    "            all_review_word_dinner[l] += 1 #その単語の登場回数を1加える\n",
    "            num_word_dinner += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"======================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"======================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['強い19',\n",
       " '美味しい8',\n",
       " '素晴らしい8',\n",
       " '高い7',\n",
       " '良い5',\n",
       " '面白い4',\n",
       " '固い3',\n",
       " 'いい3',\n",
       " 'ない2',\n",
       " 'すごい2',\n",
       " 'よい2',\n",
       " '甘い2',\n",
       " '浅い2',\n",
       " '大きい2',\n",
       " '小さい1',\n",
       " '嬉しい1',\n",
       " '柔らかい1',\n",
       " '有難い1',\n",
       " 'おかしい1',\n",
       " '多い1',\n",
       " '力強い1',\n",
       " 'たまらない1',\n",
       " '軽い1',\n",
       " '淡い1',\n",
       " 'おこがましい1',\n",
       " '硬い1',\n",
       " '難しい1',\n",
       " '白い1']"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.read_csv(store_file[0])\n",
    "results = n_gram_result(\"シャリ\", 8, df3[\"dinner_review\"])\n",
    "l = [w[0][1] + str(w[1]) for w in results]\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_gram_result_dinner(word, n, file, dinner):\n",
    "    pare_time_dic = defaultdict(int)\n",
    "    df = pd.read_csv(file)\n",
    "    if dinner == True:\n",
    "        for text in df[\"dinner_review\"]:\n",
    "            for gram in n_gram(n,text):\n",
    "                if word == gram[n][0]:\n",
    "                    for g in gram:\n",
    "                        #if word != g[0] and g[1] == \"形容詞\":\n",
    "                            #pare_time_dic[(word, g[0])] += 1\n",
    "                        if g[0] != word and g[0] != \"*\" :\n",
    "                            pare_time_dic[(word, g[0])] += 1\n",
    "    counter = Counter(pare_time_dic)\n",
    "    common = counter.most_common()\n",
    "    return common"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
